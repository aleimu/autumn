至今一切社会的历史都是阶级斗争的历史 --共产党宣言
因为bootstrap压根就不是给前端用的。这东西是给完全没有任何设计水平的后端程序员（比如我）用的。作用是在完全没有美工帮助的情况下，快速/敏捷的做出一个还看得过去的应用，并且从头到尾不用考虑如何做出xxx效果，只需要按着教程搭就行了。如果没有bootstrap，我敏捷做出来的东西根本就不能看……
有人栽树的地方，就是吉祥的地方。（茨威格《昨日的世界》）

 
 
# 科学上网 VPN
{
蓝灯 直接下载运行就行。但有流量限制
https://github.com/getlantern/lantern/releases/tag/latest
 
XX-Net 也可以但配置麻烦，需要条件。
https://github.com/XX-net/XX-Net/wiki/How-to-use

绿叶VPN
https://www.hinwen.com/32660.html

pythonweb-216209|true-oasis-216209
pythonweb-216209.appspot.com
}

# 精进你的python代码
{
    https://github.com/leinardi/pylint-pycharm
    D:\Python37\Scripts\pylint.exe
    Pylint是一个Python源代码分析器，它可以查找编程错误，帮助实施编码标准并嗅探某些代码异味
    pylint-pycharm是pycharm调用Pylint的组件，唯一需要的配置是设置Pylint可执行文件的路径，并且只有在PATH环境变量中不存在的情况下。
    当然也可以将Pylint手动配置成 External Tools，过程如下：
    https://www.cnblogs.com/gaowengang/p/7892661.html

    # 方法命名规约   

    1） 获取单个对象的方法用 get 做前缀。   
    2） 获取多个对象的方法用 list 做前缀。   
    3） 获取统计值的方法用 count 做前缀。   
    4） 插入的方法用 save（推荐）或 insert 做前缀。   
    5） 删除的方法用 remove（推荐）或 delete 做前缀。  
    6） 修改的方法用 update 做前缀。

    对于注释的要求：
    1、能够准确反应设计思想和代码逻辑；
    2、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息。
    3、好的命名、代码结构是自解释的


    特殊标记：TODO 我们经常用， FIXME 还没开发或者有错误，OTHER 需要调用别人的接口，pycharm支持todo和fixme标记
    # TODO + 说明：该注释处有功能代码待编写，待实现的功能在说明中会简略说明。
    # FIXME + 说明：该注释处代码需要修正，甚至代码是错误的，不能工作，需要修复，如何修正会在说明中简略说明。
    # XXX + 说明：代码虽然实现了功能，但是实现的方法有待商榷，希望将来能改进，要改进的地方会在说明中简略说明。

    不要在视图模板中加入任何复杂的逻辑。
    对大段代码进行 try-catch，这是不负责任的表现
    最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。
    用户请求传入的任何参数必须做有效性验证。
    表单、AJAX 提交必须执行 CSRF 安全过滤
    发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过 滤等风控策略。

    单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。
    超过三个表禁止 join。需要 join 的字段，数据类型必须绝对一致；多表关联查询时， 保证被关联的字段需要有索引。 
    SQL 性能优化的目标：至少要达到 range 级别，要求是 ref 级别，如果可以是 consts 最好

}

# cmder
{
# win10 更新后 Cmder 光标多了一个字符，怎么去除？
https://www.zhihu.com/question/58401382/answer/159072951

# cmder的user-aliases.cmd 中配置的常用别名命令
{
    e.=explorer .
    gl=git log --oneline --all --graph --decorate  $*
    ls=ls --show-control-chars -F --color $*
    pwd=cd
    clear=cls
    history=cat "%CMDER_ROOT%\config\.history"
    unalias=alias /d $1
    vi=vim $*
    cmderr=cd /d "%CMDER_ROOT%"
    ll=dir
    l=ls --show-control-chars 
    ip=ipconfig
    ifconfig=ipconfig
}

# cmd
tasklist.exe |findstr.exe mysql # 查询mysql进程
taskkill /pid 1936  # kill 
ipconfig /flushdns
}

# 给远程主机添加运行redis访问的iptable
{
https://blog.csdn.net/Shyllin/article/details/81033347 # Ubantu下通过iptables开放端口
iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 6379 -j ACCEPT     # 开放本机的6379端口
}

# 十步学习法：
{
    第一步：了解全局
    第二步：确定范围
    第三步：定义目标
    第四步：寻找资源
    第五步：创建学习计划
    第六步：筛选资源
    第七步：开始学习，浅尝辄止
    第八步：动手操作，边玩边学
    第九步：全面学习，学以致用
    第十步：乐为人师，融会贯通
    
论：结论先行，一次表达只支持一个思想，最好出现在开头。
证：以上统下，任何一个层次的思想都必须是其下一个层次的概括。
类：归类分组，每一组思想需要属于同一类范畴。
比：逻辑递进，任何一组思想，需要按照一定的逻辑顺序进行组织。
}

# 什么是结构化思考力
{

1，定义。结构思考力就是通过结构的方式来系统思考的能力，是一种强调体系化的思维方式。

2，核心理念（源于麦肯锡的“金字塔原理”）

理念一，纵向结构上的每一组的观点都必须是其下一个层次观点的概括。

理念二，横向结构上每组中的各个观点互不重叠，且有一定的逻辑顺序。

理念三，金字塔构成一个严谨的逻辑体系，通过这样的方式做总结，可以迅速抓住我们要的主旨，帮助听者沿着我们的思路去理解内容。

3，四个核心原则

原则一，论，结论先行，先说结果，后说过程。

原则二，证，经下证上，下面的数据证明上面的观点。

原则三，类，归类分组，彼此不交叉。

原则四，比，逻辑递进，有一定的逻辑顺序。常用逻辑顺序有时间，重要程度，结构顺序三种。

二，两种结构化思考的方法

一个人的大脑里有千万种纷杂的图象和信息点，经常处于无序的杂乱的无意识状态。怎样让我们的思维变得有序和清晰呢，结构化的思考工具就像一个吸附点，将各种信息分类，包括你想不到的，别人想到的，你没犯过的错，别人犯过的，让你清晰看到更多的有的和没有过的可能性，从而增加对事物的预见性和控制性。结构化思考力让原本混沌的思想，变得清晰起来，让你用结构的方式看世界，体会用思维框架来思考的魅力。


1，自上而下的结构化说服法

1）确立主题。将结论作主题，主题一定是基于谈话目标的，而且必须是一个有观点的结论，只有结论才能引发下一层级新的论证，结论先行，服务目标，表达有吸引力。越高层的领导，越是以目标为导向，他们都喜欢先听到结论。

2）设计问题。从对方角度提问，也就是换位思考，当你将自己完全代入到对方的情境中，才能看到对方想要了解的问题，对方想要的结果。这样去表达会很有说服力，因为对方关心的问题都被你一个个解答出来了。

通过5W2H确保问题被全面覆盖。5W2H（why , what , where , when , who , how ,how much )基本上涵盖了对方关心的大部分问题，从里面挑出对方最关心的问题来解答。还有简化版的2W1H( why , what , how ),这些包含了经常被问到的核心问题。

3）找好答案。提前准备好问题的答案，先准备好可能出现的问题的所有答案。说对方想要的，做话题的带领者，提高说服的效率。


2，自下而上的总结归纳法

1）理解，收集信息阶段，目标是隐性思维显性化。将一年中或一阶段中的重要的事情都罗列出来。用结构化思考来区分信息，找到信息之间的类别和关联。结构化思考帮助我们有意识地运用结构，将注意力导向一个尽可能宽广的范围，并能够时时用结构的视角来审视思维是否清晰。

2）分类（重构），收集完信息，进入思维加工阶段，目标是显性思维结构化。这里会用到“论证类比”原则，自下而上的搭建金字塔结构方法。目的是运用结构化思考的方式构建自己在思考，表达和解决问题时的结构。

首先用开放式分组，用结构思考力的MECE原则（相互独立，完全穷尽），确保把主题分清，分尽。重大议题不重叠，不遗漏，借此有效把握问题核心，并解决问题。

还可以用封闭式分组，直接调用前人总结过的思考模型。比如：SWOT分析，PEST分析，波特5力，营销4P，市场决策4P，WOOP工具，结果三律等等。

各种不同的情形，运用不同的思维工具。这些工具的应用会让你全盘考虑，不会过份关注某些细节，带给你启发和新的认识，看到以前看不到的误区和领域。带来一个更系统更全面的视角，全新审视和理解问题。当你有足够多的“工具”，你就拥有了更多的思考角度，看问题就不会遗漏，从而更接近事物的本质。那些你以前看不到深入不了的东西，都会通过工具展示在你面前。出现的很多困难也可以用IF......THEN......，提早做好预案。

3）概括总结（呈现），分好类后，就到了思维的输出阶段，目标是结构思维形象化。形象化表达是结构化思考后最有效的输出方式。比如将内容用脑图先勾勒出来。当归类分组完成后，可以将各个要点概括出一个结论，然后继续向上推论，一步步推到金字塔结构的塔顶，得出最后的结论。自下而上的概括总结，不但可以清晰观点，很多时候还可以产生新的观点。先在纸上用思维导图的形式画出来，最容易触发灵感。



三，结构化思考的意义

我们时常活在事物表面，对事物处于3S情绪，30S下意识判断中。但是运用思考结构，思考准备，可以让思考达到深入细致的程度，越来越清晰。有人用思维导图，结构思考，分析模型，为30秒的反应做了1小时的准备工作（是普通人的120倍），所以谁的判断更有价值，更准确，更有意义，这是显而易见的。

人的智商的正负差不过20%以内，而真正拉开人与人之间的差距的是这30S背后，你有没有120倍的投入。这不是聪明不聪明的问题，智慧通常与聪明无关，人们常说大智若愚，大道至简，最高级的智慧往往是最简单的，所谓聪明人下笨功夫是也。那些你看到的毫不费力，背后是付出了无数的努力才得来的。

四，结构化思考的练习

1，用以终为始的思维方式，有目的地训练自己的结构化思考力。根据学习的“721”法则，有效的学习，70%源于自己的实践练习，20%来自于他人的辅导和反馈，还有10%来源于课堂式培训学习。实践学习依托于现实场景。结构思考力不仅仅是解决问题的一种思维方式，也不限于汇报，总结，还可以用在思考，提问，学习，写作，表达和执行等生活的方方面面，这些都是生活中的应用场景，也是最主要的训练场景。

2，刻意练习。比如结构化思考力的核心思维标准有十个：识别，判断，概括，论，证，类，比，配，得，上。给自己制订一个计划，一段时间重点研究一个思维标准，并在实践中反复运用和反思。这样有目的，有目标地去练习才会取得好的效果。

3，每天深入解决一个问题。每天选择一个问题进行深入思考，尝试用论证类比的方法，找出看待同一个问题的各个维度和要素，多视角思维，锻炼自己的思考习惯。

4，复盘。每天睡觉前花一点时间做个回顾和反思，看看每天在思考问题解决问题方面那些做得好的，运用了那些思维方法，有那些做得不好的，还可以用什么思维方法，有没有围绕中心目标。将思考记录下来，并定期回顾。


作者：木林心慢
链接：https://www.jianshu.com/p/07172feba708
來源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。



年轻的时候，我们总是会将自己的创作冲动误解为创作才能------钱钟书



# 带着问题阅读：

1、这本书到底在谈些什么？

2、作者如何依次发展这个主题，如何逐步从核心主题分解出从属的关键议题来？

3、作者细部说了什么，怎么说的？你一定要想办法找出主要的想法、声明与论点。

4、这本书说得有道理吗？是全部有道理，还是部分有道理？

5、这本书跟你有什么关系？

6、用自己的语言重述这本书的知识？

7、描述自己的相关经验，我以后怎么用？


作者：可乐君CC
链接：https://www.jianshu.com/p/c8e3e5c97ffe
來源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。

#  http://blog.sina.com.cn/s/blog_471facb1010000ed.html
#  金字塔原理主要适用于公文和商务类写作，不要写啥都用，以免走火入魔。


对于金字塔每一层的支持论据，有个极高的要求：MECE（Mutually exclusive and collectively exhaustive），即彼此相互独立不重叠，但是合在一起完全穷尽不遗漏。不遗漏才能不误事，不重叠才能不做无用功。

金字塔原则看似废话，但确实是一个伟大的原则，一个伟大的方法论。
伟大用途之一，解决问题：当你尝试解决问题时，你从下到上，收集论据，归纳出中心思想，从而建造成坚实的金字塔。有了这个大致的目标，问题解决起来最有效。
伟大用途之二，管理手下：如果你是领导，有经验，有手下，对于某个问题，你根据经验提出假设，迅速列出第一级三至七个支持论据，分别交待给不同的手下。两周后，手下提交报告，你汇总排列，从而建造成坚实的金字塔。有了这个原则，管理起来最有效，领导做得最轻松。
伟大用途之三，交流成果：问题已经解决，金字塔已经建成，需要交流的时候，你从上到下，从金字塔尖尖向领导汇报。过去皇帝早朝殿议，给你三分钟，现在你在电梯里遇到领导，给你三十秒，你只汇报中心论点和一级支持论据，领导明白了，事情办成了。如果领导和刘备一样三顾你的茅庐，而且臀大肉沉，从早饭坐到晚饭，吃空你家冰箱。你有讲话的时间，他有兴趣，你就汇报到第十八级论据，为什么三分天下，得蜀而能有其一。有了这个原则，交流起来最有效。

作为中国人，需要小心的是，我们传统上日常生活的交流，不是从金字塔尖尖到金字塔基底的，而是相反。比如我们通常这样对小王的妈妈说：小王吃喝嫖赌抽，坑蒙拐骗偷，打瞎子骂哑巴，挖绝后坟瞧寡妇门，小王是个坏蛋。我们通常不这样对小王妈妈说：小王是个坏蛋。然后看看小王妈妈的反应，再进一步提供证据：小王吃喝嫖赌抽，坑蒙拐骗偷，打瞎子骂哑巴，挖绝后坟瞧寡妇门。纯用金字塔原则交流，在中国，容易找抽。



手把手教学 VS 提要式教学

# 什么叫选择适合自己的书？
用得上、看得懂


“事非宜，勿轻诺。苟轻诺，进退错。”《弟子规》

人的生活就像投资品价值一样，是存在均值回归的。那个均值，就是你内心最深处的冲动，是你真正的欲望，是你到底是一个什么样的人。

人生任何一个阶段的“筛选”都只是一种形式，别被这些一时的标准迷惑。定义你最终归宿的，一定是你能力和欲望综合的那个真实的你。

如果一样东西，你五句话没有说清楚，那十句话也是说不清楚的，还是自己没有真的搞明白。

好闻的香味能使人安定
}

# mmap 共享内存(虚拟内存映射文件)
{
mmap是一种虚拟内存映射文件的方法，即可以将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。
普通文件被映射到虚拟地址空间后，程序可以像操作内存一样操作文件，可以提高访问效率，适合处理超大文件，还有一个用途是在不同进程间共享内存

# 参考博客
http://www.cnblogs.com/Security-Darren/p/4733387.html
http://www.cnblogs.com/zhoujinyi/p/6062907.html
https://www.cnblogs.com/dkblog/archive/2011/03/14/1983250.html

}

# 关于keep-alive的几点疑惑
{
一、http的keep-alive与tcp的keep-alive 
http keep-alive： 
在一次tcp连接中可以连续发送多次数据，即可以保持一段时间的tcp连接，在这个保持的通道上有多个request、多个response。而不用每发一次数据就要重新进行三次握手连接，发完一次数据就要立即进行四次挥手释放连接。 这样可以提高性能和吞吐率。

tcp keep-alive： 
为了检测tcp的连接状况。经过设定的时间之后，服务器会发出检测包去确认tcp连接是否还在。如果出现了问题就关闭连接。

小结：http的keep-alive和tcp的keep-alive是完全不同的东西。

二、request header中的http keep-alive与tcp连接 
在http1.1版本之后都会默认设置connection为keep-alive，如果想要关闭这条设置，需要在头信息中更改connection为close。

但是在实际使用中，http头部有了keep-alive这个值并不代表一定会使用长连接，客户端和服务器端都可以无视这个值，每一条TCP通道，只有一次GET，GET完之后，立即有TCP关闭的四次握手，这样写代码更简单。这时候虽然http头有connection: keep-alive，但不能说是长连接。所以是否用了长连接，还是得用抓包工具分析tcp流。

小结：正常情况下客户端浏览器、web服务端都有实现这个标准，因为它们的文件又小又多，保持长连接减少重新开TCP连接的开销很有价值。但是最终到底有没有实现keep-alive还是得看tcp流的情况。

三、http keep-alive的tcp复用与websocket长连接 
http keep-alive： 
http keep-alive只是一种为了达到复用tcp连接的“协商”行为，双方并没有建立正真的连接会话，服务端也可以不认可，也可以随时（在任何一次请求完成后）关闭掉。它是指在一次 TCP 连接中完成多个 http请求，但是对每个请求仍然要单独发 header，所以除了真正的数据部分外，服务器和客户端还要大量交换http header，信息交换效率很低，这样建立的“长连接”都是伪长连接。

websocket： 
websocket不同，它本身就规定了是正真的、双工的长连接，两边都必须要维持住连接的状态。

小结：http协议决定了浏览器端总是主动发起方，http的服务端总是被动的接受、响应请求。http提供的长连接服务器可以不接受。而websocket协议，在连接之后，客户端、服务端是完全平等的。websocket是真正的长连接。

# https://blog.csdn.net/sumdeveloper/article/details/78670313?utm_source=copy 

}

# 媚俗，媚美，眩惑
{
媚俗一词源于德语的Kitsch，被米兰·昆德拉在多次演讲中引用。“媚俗”的意思指的就是低级，庸俗的意思。20世纪，艺术商品化的泛滥，造成艺术本身的异化，使得票房价值代替审美价值，表面的暂时的轰动效应代替较持久的审美效应，浅薄的娱乐、消遣功能代替了艺术的社会批判功能倾向和陶冶功能。在商品市场的“感召”下，文艺走向了一个极端，畸形的倾向：媚俗。鲍德里亚在《消费社会》一书中对“媚俗”做了如下阐述：“当代物品中一个主要的、带有摆设的范畴，便是媚俗。它把自己定义为伪物品，定义为模拟、复制、仿制品、铅板。”媚俗的激增是由工业备份、平民化导致的，它在消费社会社会学现实中的基础，便是大众文化（Popular Culture）。这就导致了精英文化逐渐被大众文化的流行所覆盖，毫无特性的、同质性的、媚俗的因素充斥了整个消费社会。
媚美来自叔本华，叔本华认为美有三种形态，一是壮美，二是优美，三是媚美，壮美与优美才是真正的美，而媚美严格说来不是美，因为，在叔本华看来，美是超越功利与欲求的，而媚美，分成积极的与消极的两种。前一种是功利的，寻求感官刺激的。那种令人产生肉欲的裸体画与雕塑也属于这一类。第二种媚美是消极的媚美，它比之积极的媚美，更糟，因为它是矫情的作品，不真实，不自然，不合理，是乱七八糟的拼凑物，然外表华丽。叔本华说它是“令人厌恶作呕的东西”。王国维将这种媚美称之为“眩惑”。



每一个政治正确的背后是赤果果的利益，甚至是人头滚滚血流成河。
因为双方和多方，该流的血也流的差不多了，剩下的人可以暂时坐下来分享利益了，才有了政治正确。


你批评别人的时候，要记住，并不是世界上所有人都和你有一样的条件。----《了不起的盖茨比》
永远不惮以最坏的恶意，揣度强权的动机，以保持自身的独立与清醒

米兰昆德拉提出媚俗这个概念，并不是要让大家去分辨，什么是媚俗，什么是不媚俗，而是让大家明白，在直面自己的道路上，有许多障碍需要克服，对自己真诚。


刻奇让我们渺小的生命更有种意义感。同时，这也是一种融入世界的方式。为人类所共有的情感得到发现，我们的生命意义得到认可。

我更惧怕我对生命失去敬畏、对家人失去情感、对人生百态冷漠。


取悦自己 VS 取悦大众


我认为昆德拉提出“媚俗”概念本身的意义并不是让大家反对它，而是通过认识和分析“媚俗”对于个人和集体的作用来修正自己的认知和行为，不盲从也不盲独。而只是为了反对媚俗而选择特立独行，实际上只是一种更大的遗憾。

老实说我认为现在人们因为意识到了媚俗的存在而选择特立独行只不过是一种中二的行为罢了。无论是否承认，我们都只是普普通通的存在，这个社会不会因为我们的选择或者不选择而改变什么，这种“反媚俗”也不会给我们带来过多实际的益处，最多不过是知道的更多一点罢了，仅此而已，而只是为此而让自己置身于社交之外的话又实在是得不偿失。

只是为了生存，我开始接纳它，以它的规则行事，为了谋求更多生存空间。可以说，这是一种妥协，而让生活把自己变得庸俗不堪。但我知道我终究知道自己内心是有更多的思考的，只不过这些想法于生活、于社会都不会有什么作用的。我所说的这些也只不过是聊以自慰罢了，表示自己不甘的态度而已。


自省自觉自明，于是自然

他们做的往往并非他们内心真正渴望的。他们都有一种群居意识，惧怕被疏离与被排斥，惧怕孤单无依靠。

无论是媚俗还是刻奇，都是源于心理上对他人认同的需求。

媚俗：即迎合受众，取悦他人。

媚不俗：媚不俗是意识到媚俗后的行为反应，主要体现在向往存在感并有强烈自我意识的个体，媚不俗的行为不是来源于真实的自我追求，而是来源于与俗的对立，为了不媚俗而媚不俗。

刻奇：情感上迎合自己，自我感动及感伤。


针对自己的建议：善用敏感和自我意识，不要过度的自省，尽量专注于所做的事情，不要过多专注内心的感受。

你满足了人的劣根性，必然被劣根性打倒。
迁就不合理也不应该被满足的需求是一切生意衰败的开始。
}

# celery-dome
{
```python
pip install celery
pip install redis

# celery1.py
from celery import Celery
broker = "redis://127.0.0.1:6379/0"
backend = "redis://127.0.0.1:6379/0"
app = Celery("celery1", broker=broker, backend=backend)
@app.task
def add(x, y):
    return x+y

# 启动Celery Worker开始监听并执行任务
celery -A celery1 worker --loglevel=info

# 调用任务
import time
from celery1 import add
re = add.delay(10, 20)
print(re)           # 723195f4-0baf-41f2-800b-e194604f42e1
print(re.status)
time.sleep(8)
print(re.status)    # SUCCESS
print(re.result)    # 30
```

# redis 中的key-value情况
127.0.0.1:6379> keys *
1) "celery-task-meta-723195f4-0baf-41f2-800b-e194604f42e1"
2) "_kombu.binding.celeryev"
3) "device:web_operator"
4) "_kombu.binding.celery"
5) "_kombu.binding.celery.pidbox"

127.0.0.1:6379> GET "celery-task-meta-723195f4-0baf-41f2-800b-e194604f42e1"
"{\"status\": \"SUCCESS\", \"traceback\": null, \"result\": 30, \"task_id\": \"723195f4-0baf-41f2-800b-e194604f42e1\", \"children\": []}"

127.0.0.1:6379> smembers  "_kombu.binding.celeryev"
1) "worker.#\x06\x16\x06\x16celeryev.b5e20077-a8f2-4c7b-9e60-9f8af8f79066"
127.0.0.1:6379> smembers "_kombu.binding.celery"
1) "celery\x06\x16\x06\x16celery"
127.0.0.1:6379> smembers "_kombu.binding.celery.pidbox"
1) "\x06\x16\x06\x16celery@(none).celery.pidbox"

}

# before_request after_request teardown_request
{
@main.route('/', methods=['GET'])
def index():
    resp = jsonify({'error':False})
    # 跨域设置
    resp.headers['Access-Control-Allow-Origin'] = '*'
    return resp


@app.route('/articles_list/contents/')
def json_contents():
    response = make_response(jsonify(response=get_articles(ARTICLES_NAME)))
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = 'POST'
    response.headers['Access-Control-Allow-Headers'] = 'x-requested-with,content-type' 
    return response

    

before_request :在请求收到之前绑定一个函数做一些事情。
after_request: 每一个请求之后绑定一个函数，如果请求没有异常。
teardown_request: 每一个请求之后绑定一个函数，即使遇到了异常。

在每个请求之前，执行 before_request() 上绑定的函数。 如果这些函数中的某个返回了一个响应，其它的函数将不再被调用。任何情况下，无论如何这个返回值都会替换视图的返回值。
如果 before_request() 上绑定的函数没有返回一个响应， 常规的请求处理将会生效，匹配的视图函数有机会返回一个响应。
视图的返回值之后会被转换成一个实际的响应对象，并交给 after_request() 上绑定的函数适当地替换或修改它。
在请求的最后，会执行 teardown_request() 上绑定的函数。这总会发生，即使在一个未处理的异常抛出后或是没有请求前处理器执行过 （例如在测试环境中你有时会想不执行请求前回调）。


    
@app.teardown_request
def teardown_request(response):     # response 传入的是什么？什么情况下有不是None？
    print("teardown_request response:", response)   # ('teardown_request response:', None)
    db.session.remove()
    db_carrier.session.remove()

@app.after_request
def after_request(response):     # response 是每个请求的 response 
    print("after_request response:", response)      # ('after_request response:', <Response 3884 bytes [200 OK]>)
    response.headers['Content-Type'] = 'text/html'  # 避免ie8把json数据以下载方式打开
    return response

    
# 自定义的装饰器 应该放在 @user.route('/datum') 下面才能在每次请求发生时生效！！！！

@allow_cross_domain # 无效
@user.route('/datum')
@validate_params(required=['datum_id']) # 有效
def get_user_datum():
    pass

}
    
# nginx
{
    
rewrite_log on;   # 打开 URL 重写模块的日志开关，以便写入 error_log
access_log /var/log/nginx/images.log;


location [=|~|~*|^~] patt {

}

=:严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。
~:为区分大小写匹配(可用正则表达式)。
~*:为不区分大小写匹配(可用正则表达式)。
^~:如果把这个前缀用于一个常规字符串,那么告诉nginx 如果路径匹配那么不测试正则表达式。



location / {
    include uwsgi_params;
    rewrite ^/$ /static/content/userManager/driver_view.html redirect;
    uwsgi_pass unix:/root/new_test_01/servers/sub_operation/backend_oper/op_test_01.sock;
}
location ^~ /static/ {
    root /root/new_test_01/servers/web_front/oper_web/;
    index login.html;
}
location ^~ /upload/ {
    access_log /var/log/nginx/images.log;
    alias /root/new_test_01/servers/uploads/camel_uploads/;
    autoindex on;
}
location ~ .*\.(gif|jpg|jpeg|bmp|png|ico|txt)$  {
    access_log /var/log/nginx/images.log;
    #root /root/new_test_01/servers/sub_operation/backend_oper/instance/static/;
    #alias /root/new_test_01/servers/uploads/camel_uploads/;
    root /root/new_test_01/servers/uploads/camel_uploads/;
    autoindex on;
}




location  = / {
  # 只匹配”/”.
  [ configuration A ] 
}
location  / {
  # 匹配任何请求，因为所有请求都是以”/“开始
  # 但是更长字符匹配或者正则表达式匹配会优先匹配
  [ configuration B ] 
}
location ^~ /images/ {
  # 匹配任何以 /images/ 开始的请求，并停止匹配 其它location
  [ configuration C ] 
}
location ~* \.(gif|jpg|jpeg)$ {
  # 匹配以 gif, jpg, or jpeg结尾的请求. 
  # 但是所有 /images/ 目录的请求将由 [Configuration C]处理.   
  [ configuration D ] 
}


# 请求URI例子:

/ -> 符合configuration A
/documents/document.html -> 符合configuration B
/images/1.gif -> 符合configuration C
/documents/1.jpg ->符合 configuration D

# 去掉url中的page字段
rewrite '^/page/static/(.*)\.*' '/static/$1' permanent;     # 66666

}

# CSRF（Cross-site request forgery）跨站请求伪造：攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。
{
一个典型的CSRF攻击有着如下的流程：

受害者登录a.com，并保留了登录凭证（Cookie）。
攻击者引诱受害者访问了b.com。
b.com 向 a.com 发送了一个请求：a.com/act=xx。浏览器会默认携带a.com的Cookie。
a.com接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求。
a.com以受害者的名义执行了act=xx。
攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让a.com执行了自己定义的操作。

}

# 性格成因 -----还是没有搞清楚
{
上面说性格成因，先天基因占50%，后天环境占50%，这是原来比较早期的实验结果。今天早上看了几个正在进行的、对这个观点进一步证实的研究的数据，涉及几个巨大的样本，分别是大学生若干千人，60年跟踪调查一千多人，5-10岁的小孩几千人。研究的基本方法是用五大性格模型，对父代和子代的性格进行对比，发现父代和子代的性格相关只有r=0.15。这是一个非常小的相关效果，比理论上预计单独基因的效果（r=0.25）还要小。研究还对父母的某些特定行为对性格的影响做了相关，还有出生顺序（birth order，你是家里老大、老二、老末什么的）对性格的影响，这些基本上都是r=0.0几上下。几乎没影响。虽然这里有些研究还没有发表，数据还在整理阶段，但一旦发表应该会引起巨大震动。这些数据的意义在于：人的性格成因非常复杂，有很多因素，但各个因素都只有很小的效果，没有一个决定性的东西可以被认为是人类性格的主要成因（比如父母高C，你就高C，父母的决定性并没有这么大）。当然对于每个人的情况，可能因人而异，各有不同，但就人类整体而言，目前没发现一个决定性的因子。

作者：程毅南
链接：https://www.zhihu.com/question/20513133/answer/15344031

前者是因为路径依赖，后者是因为习得性无助。所以，成功才是成功之母！

答案是血糖，或者跟血糖 coefficient 的某种生理资源。
其他答案基本胡扯。

基因决定的生理舒适“设定点”。设定点指的是一个人大脑和身体功能的最佳和最自如的状态，参数包括体温、血压、血糖、心率等。
}

# python 查缺补漏
{
# JG_Carrier.query.filter(statment) 不可以写成JG_Carrier.query(JG_Carrier.XXX,JG_Carrier,XXXXX).filter(statment) 
curl 'http://172.16.2.192:3000/conformation/?token=ST-1302-XnSTxhZHKMEhJHF6mPey-cas01.example.org&id=&name='  会是 p_id="",p_name="" 达不到下面的效果。
p_id = request.values.get('id', "999999")
p_name = request.values.get('name', "总公司")

curl 'http://172.16.2.192:3000/conformation/?token=ST-1302-XnSTxhZHKMEhJHF6mPey-cas01.example.org' 才能触发默认值。

# 还有这样强转类型的骚操作啊
>>> type('a')(1)
'1' 

# python中 not, and, or 的优先级

not > and > or
# or 从左到右计算表达式，返回第一个为真的值
# and 从左到右计算表达式，若所有值均为真，则返回最后一个值，若存在假，返回第一个假值
# 全为 true 的情况下:
and:取大
>>>3 and 4
4
>>> 5 and 6
6
or:取前
>>>3 or 4
3
>>>6 or 5

In [17]: 2 or 3 or 4
Out[17]: 2

In [18]: 2 and 3 and 4
Out[18]: 4


# string 
In [34]: a='{0}, {1}, {2}'
In [35]: a.format('a','b','c')
Out[35]: 'a, b, c'

In [36]: b='%s,%s,%s'
In [37]: b
Out[37]: '%s,%s,%s'
In [38]: b % ('a','b','c')
Out[38]: 'a,b,c'


In [51]: from string import Template
In [52]: s = Template('$who likes $what')
In [53]: s.substitute(who='tim', what='kung pao')
Out[53]: 'tim likes kung pao'

In [47]: Template('$who likes $100').safe_substitute(dict(who='me'))
Out[47]: 'me likes $100'

# difflib为python的标准库模块，无需安装。对比两个文本、两个序列之间的差异。并且支持输出可读性比较强的HTML文档，与LInux下的diff 命令相似。在版本控制方面非常有用。

# 几种格式可以与dict互转
In [145]: c=((1,2),(3,4))
In [146]: dict(c)
Out[146]: {1: 2, 3: 4}

In [151]: a=[[1,2],[3,4]]
In [152]: dict(a)
Out[152]: {1: 2, 3: 4}

In [153]: a=[(1,2),(3,4)]
In [154]: dict(a)
Out[154]: {1: 2, 3: 4}

In [155]: a=([1,2],[3,4])
In [156]: dict(a)
Out[156]: {1: 2, 3: 4}


In [162]: b={1: 2, 3: 4}
In [163]: set(b)
Out[163]: {1, 3}
In [164]: list(b)
Out[164]: [1, 3]


# {} 是dict 非空就是set
In [175]: type({})
Out[175]: dict

In [176]: type({1,2,3})
Out[176]: set

In [177]: type(())
Out[177]: tuple

In [178]: type([])
Out[178]: list



# Python2.7 - Python3.7  都有这个问题
>>> a=(1,2,[1,2,3,4,5])
>>> a[2]+=[1,1,1]
Traceback (most recent call last):
  File "<pyshell#1>", line 1, in <module>
    a[2]+=[1,1,1]
TypeError: 'tuple' object does not support item assignment
>>> a
(1, 2, [1, 2, 3, 4, 5, 1, 1, 1])
>>> a[2].extend([2,2,2])
>>> a
(1, 2, [1, 2, 3, 4, 5, 1, 1, 1, 2, 2, 2])
>>> 





# 如何快速反转字符串？
    #Bad
    a = 'Python is a powerful languange.'

    list_a = list(a)
    list_a.reverse()
    re_a = ''.join(list_a) 

    #Good
    a = 'Python is a powerful languange.'
    re_a = a[::-1]



# 把列表分割成同样大小的块？
    a = [1, 2, 3, 4, 5, 6]
    list(zip( *[iter(a)]*2 ))
    >>> [(1, 2), (3, 4), (5, 6)]


    #合并list相邻项
    a = [1, 2, 3, 4, 5, 6]

    list(zip( a[::2], a[1::2] ))
    >>> [(1, 2), (3, 4), (5, 6)]


# 交换dict的键值

    # Bad
    a = {'a': 1, 'b': 2, 'c': 3, 'd': 4}

    def reverse_dict(a):
        new_dict = {}
        for k,v in m.items():
            new_dict[v] = k
        return new_dict

    # Good
    a = {'a': 1, 'b': 2, 'c': 3, 'd': 4}

    def reverse_dict(a):
        k = a.keys()
        v = a.values()
        new_dict = dict(zip(v, k))
        return new_dict
    
    
# 使用 Counter 进行计数统计
    >>> from collections import Counter
    >>> Counter(s=3, c=2, e=1, u=1)
    Counter({'s': 3, 'c': 2, 'u': 1, 'e': 1})

    >>> some_data=('c', '2', 2, 3, 5, 'c', 'd', 4, 5, 'd', 'd')
    >>> Counter(some_data).most_common(2)
    [('d', 3), ('c', 2)]
    >>> some_data=['c', '2', 2, 3, 5, 'c', 'd', 4, 5, 'd', 'd']
    >>> Counter(some_data).most_common(2)
    [('d', 3), ('c', 2)]
    >>> some_data={'c', '2', 2, 3, 5, 'c', 'd', 4, 5, 'd', 'd'}
    >>> Counter(some_data).most_common(2)
    [('c', 1), (3, 1)]




#避免类初始化时大量重复的赋值语句
    class A(object):
        def __init__(self, a, b, c, d, e, f):
            self.__dict__.update({k: v for k, v in locals().items() if k != 'self'})
        
        
# 解密PYC 文件很简单
    >>> import dis, marshal
    >>> with open('hello.pyc', 'rb') as f:
    ...     f.seek(8)
    ...     dis.dis(marshal.load(f))


# for else值得说下。不break的话就执行else

    for i in range(10):
        if i == 10:
            break
        print(i)
    else:
        print('10不在里面！')
        
    相当于：flag = False

    for i in range(10):
        if i == 10:
            flag = True
            break
        print(i)
    if not flag:
        print('10不在里面！')

# 倒序
    >>> a = "live"
    >>> a[::-1]
'evil'
# 数制转换
    >>> int('1000', 2)
    8
    >>> int('A', 16)
    10


# 闭包中的自由变量之坑
    >>> funcs = [lambda x: x*i for i in range(10)]
    >>> [f(1) for f in funcs]
    [9, 9, 9, 9, 9, 9, 9, 9, 9, 9]

    正确写法：
    >>> funcs = [lambda x, i=i: x*i for i in range(10)]
    >>> [f(1) for f in funcs]
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

# try…finally…语句中，try中的return会被直接忽视，因为要保证 finally 能够执行。
    def some_func():
        try:
            return 'from_try'
        finally:
            return 'from_finally'
    Output:

    >>> some_func()
    'from_finally'
    
# 用for写死循环
    for i in iter(int, 1):pass
    由于int() 永远返回0，永远返回不了1

}

# apt常用命令
{
apt-cache search package 搜索包
apt-cache show package 获取包的相关信息，如说明、大小、版本等
sudo apt-get install package 安装包
sudo apt-get install package - - reinstall 重新安装包
sudo apt-get -f install 强制安装
sudo apt-get remove package 删除包
sudo apt-get remove package - - purge 删除包，包括删除配置文件等
sudo apt-get autoremove 自动删除不需要的包
sudo apt-get update 更新源软件列表信息（注意只是更新列表，并未更新程序，后接apt-get upgrade）
sudo apt-get upgrade 更新已安装的包
sudo apt-get dist-upgrade 版本升级
sudo apt-get dselect-upgrade 使用 dselect 升级
apt-cache depends package 了解使用依赖
apt-cache rdepends package 了解某个具体的依赖
sudo apt-get build-dep package 安装相关的编译环境
apt-get source package 下载该包的源代码
sudo apt-get clean && sudo apt-get autoclean 清理下载文件的存档
sudo apt-get check 检查是否有损坏的依赖

}

# pip 常用命令
{
apt-get install libevent-dev
apt-get install python-all-dev
pip install --upgrade setuptools pip
pip install gevent



pip install keras==2.1.0    # 安装指定版本
pip install –upgrade keras==2.1.0   #升级package到指定版本
pip install --no-index -f=<目录>/ <包名>    # 安装本地安装包
pip uninstall <包名> 或 pip uninstall -r requirements.txt  # 卸载包
pip install -U <包名> #升级包 pip install <包名> --upgrade
pip install -U pip  # 升级pip
pip show -f <包名>    # 显示包所在的目录
pip search <在线搜索关键字>  # 搜索包
pip list -o # 查询可升级的包
pip install <包名> -d <目录> 或 pip install -d <目录> -r requirements.txt  # 下载包而不安装
pip wheel <包名>  # 打包
pip install <包名> -i https://mirrors.aliyun.com/pypi/simple  # 指定单次安装源
# 更换国内pypi镜像
    阿里：https://mirrors.aliyun.com/pypi/simple
    中国科学技术大学：http://pypi.mirrors.ustc.edu.cn/simple/

# 指定全局安装源
    在unix和macos，配置文件为：$HOME/.pip/pip.conf
    在windows上，配置文件为：%HOME%\pip\pip.ini
    [global]
    timeout = 6000
      index-url = https://mirrors.aliyun.com/pypi/simple
      
当我们在受限于网络或IO的函数中使用gevent，这些函数会被协作式的调度， gevent的真正能力会得到发挥。Gevent处理了所有的细节， 来保证你的网络库会在可能的时候，隐式交出greenlet上下文的执行权。

}

# top
{
top   //每隔5秒显式所有进程的资源占用情况
top -d 2  //每隔2秒显式所有进程的资源占用情况
top -c  //每隔5秒显式进程的资源占用情况，并显示进程的命令行参数(默认只有进程名)
top -p 12345 -p 6789//每隔5秒显示pid是12345和pid是6789的两个进程的资源占用情况
top -d 2 -c -p 123456 //每隔2秒显示pid是12345的进程的资源使用情况，并显式该进程启动的命令行参数
}

# Ubuntu iptables的防火墙UFW是配置工具
{
# 常用命令
sudo ufw enable # 启动
ufw disable # 停止
ufw default deny # 设置默认外部无法连接本机
ufw allow|deny service # 允许或拒绝某个连接,service查看etc/services中可知
ufw status # 查看ufw状态
 
# 举例
sudo ufw deny 22/tcp # 禁止本机服务 则22端口的ssh服务,外部就无法连接.
sudo ufw deny from ip   # 禁止外部连接
sudo ufw allow smtp #  允许 smtp 端口
sudo ufw delete allow smtp  # 删除 smtp 端口的许可
sudo ufw allow from 192.168.254.254 # 允许某特定 IP
sudo ufw delete allow from 192.168.254.254  # 删除上面的规则

# 配置文件/etc/ufw/ufw.conf 设置是否开机启动ufw,和设置日志级别

}

# SQLAlchemy基本操作和常用技巧
{
# 代码中session.query方法会返回一个Query对象。此后，调用Query对象的filter_by方法进行查询。它返回的依然是Query对象。最后调用Query对象的first方法获得查询记录的第1条记录。如果查询记录为空，则返回None。
ser = session.query(User).filter_by(name="user1").first()
print "%s %s" % (user.name, user.password)

# 更新记录
user = session.query(User).filter_by(name="user1").first()
user.password = "newpassword"
session.commit()

# 删除记录
user = session.query(User).filter_by(name="user1").first()
session.delete(user)
session.commit()

# sqlalchemy插入操作后自动返回自增ID
result = session.execute('insert into ***')
session.commit()
last_insert_id = result.lastrowid

}


zip -r aa.zip aa/ -x aa/upload/*
select distinct(delete_flag) from user;

Flask+Gunicorn+Gevent+Supervisor+Nginx生产环境部署


# cmder 快捷
可以利用Tab，自动路径补全；
可以利用Ctrl+T建立新页签；
利用Ctrl+W关闭页签;
还可以透过Ctrl+Tab切换页签;
Alt+F4：关闭所有页签
Alt+Shift+1：开启cmd.exe
Alt+Shift+2：开启powershell.exe
Alt+Shift+3：开启powershell.exe (系统管理员权限)
Ctrl+1：快速切换到第1个页签
Ctrl+n：快速切换到第n个页签( n值无上限)
Alt + enter： 切换到全屏状态；
Ctr+r 历史命令搜索;
End, Home, Ctrl : Traversing text with as usual on Windows


1、能同步实现的代码，就不要用异步；
2、能实时实现的代码，就不要用定时；
3、能用数据源读取的，就不要用缓存。
先保证程序简洁，满足性能要求，等遇到问题的时候，再去优化，避免过早优化，引入问题。

# substring_index(str,substr,1)：返回字符substr在str中第n次出现位置之前的字符串;
select *,substring_index(full_distance,'.0',1) as full_distance  from line limit 1\g;
select *,cast(full_distance as float) from line limit 1\g;

{
if( expr1 , expr2 , expr3 )

expr1 的值为 true，则返回值为 expr2 
expr1 的值为false，则返回值为 expr3
查找出售价为 50 的书，如果是 java 书的话，就要标注为 已售完 
那么对应的sql语句该怎样去写呢？

select *,if(book_name='java','已卖完','有货') as product_status from book where price =50


ifnull 表达式
ifnull( expr1 , expr2 )

在 expr1 的值不为 null的情况下都返回 expr1，否则返回 expr2，如下：

select ifnull(null,"11");
-> 11

select ifnull("00","11");
-> 00


sql---在查询语句中将float转换为int
select cast((f4+f5)/2 as int)  from e			
where f4 - f5 < 3 and f4 - f5 > -3
select sum(cast(a as float)) suma from table where a <> ‘张三’

mysqld.exe --defaults-file="d:\soft\mysql-5.7\my.ini"
mysqld.exe --defaults-file="d:\soft\mysql-5.7\my.ini" --console     # console 打印日志到控制台
}

# 小米开源的一款sql优化工具 soar，能给出优化建议和重写
{
echo "select a from tb" |soar.windows-amd64 -only-syntax-check

soar -report-type duplicate-key-checker -query 'use db' # check total database
soar -report-type duplicate-key-checker -query 'use db; desc tb1;desc tb2;' # check tb1, tb2


./soar -query "create table a (a int);insert into a values(1)" -report-type=fingerprint

soar.windows-amd64 -query "create table a (a int);insert into a values(1)" -report-type=fingerprint

soar.windows-amd64 -query "select * from user where id=1"

}

mysql 分库、分表、分区
数据库架构设计要根据业务量，确保安全，循序渐进，大概是 数据结构->查询语句->索引->分表->分库->主从->分布式。
对于分库分表后对数据库，业务逻辑会发生较大变化，建议根据分库表策略，编写中间件，以实现业务层和数据层的解藕。
{
# https://www.cnblogs.com/sunny3096/p/8595058.html Mysql分库分表方案
# https://www.cnblogs.com/johnnyzhang/articles/2648669.html 分表的几种常见策略
# https://www.cnblogs.com/phpshen/p/6198375.html mysql的分区和分表
# https://blog.csdn.net/zzy7075/article/details/70054818  mysql分表和表分区详解

1、水平分割：
例：QQ的登录表。假设QQ的用户有100亿，如果只有一张表，每个用户登录的时候数据库都要从这100亿中查找，会很慢很慢。如果将这一张表分成100份，每张表有1亿条，就小了很多，比如qq0,qq1,qq1...qq99表。
用户登录的时候，可以将用户的id%100，那么会得到0-99的数，查询表的时候，将表名qq跟取模的数连接起来，就构建了表名。比如123456789用户，取模的89，那么就到qq89表查询，查询的时间将会大大缩短。
这就是水平分割。
2、垂直分割：
垂直分割指的是：表的记录并不多，但是字段却很长，表占用空间很大，检索表的时候需要执行大量的IO，严重降低了性能。这时需要把大的字段拆分到另一个表，并且该表与原表是一对一的关系。
例如学生答题表tt：有如下字段：
Id name 分数 题目 回答
其中题目和回答是比较大的字段，id name 分数比较小。
如果我们只想查询id为8的学生的分数：select 分数 from tt where id = 8;虽然知识查询分数，但是题目和回答这两个大字段也是要被扫描的，很消耗性能。但是我们只关心分数，并不想查询题目和回答。这就可以使用垂直分割。我们可以把题目单独放到一张表中，通过id与tt表建立一对一的关系，同样将回答单独放到一张表中。这样我们插叙tt中的分数的时候就不会扫描题目和回答了。

以mysql为例讲述下水平拆分和垂直拆分，mysql能容忍的数量级在百万静态数据可以到千万

# 垂直拆分：
解决问题：表与表之间的io竞争
不解决问题：单表中数据量增长出现的压力
方案：
把产品表和用户表放到一个server上
订单表单独放到一个server上

# 水平拆分：
解决问题：单表中数据量增长出现的压力
不解决问题：表与表之间的io争夺
方案：
用户表通过性别拆分为男用户表和女用户表
订单表通过已完成和完成中拆分为已完成订单和未完成订单
产品表 未完成订单放一个server上
已完成订单表盒男用户表放一个server上
女用户表放一个server上


什么是分区？

分区和分表相似，都是按照规则分解表。不同在于分表将大表分解为若干个独立的实体表，而分区是将数据分段划分在多个位置存放，可以是同一块磁盘也可以在不同的机器。分区后，表面上还是一张表，但数据散列到多个位置了。app读写的时候操作的还是大表名字，db自动去组织分区的数据。

mysql分表和分区有什么联系呢？
1.都能提高mysql的性高，在高并发状态下都有一个良好的表现。
2.分表和分区不矛盾，可以相互配合的，对于那些大访问量，并且表数据比较多的表，我们可以采取分表和分区结合的方式（如果merge这种分表方式，不能和分区配合的话，可以用其他的分表试），访问量不大，但是表数据很多的表，我们可以采取分区的方式等。
3.分表技术是比较麻烦的，需要手动去创建子表，app服务端读写时候需要计算子表名。采用merge好一些，但也要创建子表和配置子表间的union关系。
4.表分区相对于分表，操作方便，不需要创建子表。


}

Innodb引擎适用场景
1.需要事务的操作；
2.更新数据需要使用行级锁；
3.大数据量读写；
4.大型互联网应用。


MyISAM引擎适用场景
1.不需要事务的操作；
2.插入、更新少，读取频繁；
3.频繁的统计计算。

接收到SQL --> 放入SQL执行队列 --> 使用分析器分解SQL --> 按照分析结果进行数据的提取或者修改 --> 返回处理结果。在这个过程中一般比较花时间的是在队列里的等待时间和执行时间。归根到底就是执行时间，执行时间减少了等待时间自然就变短了。

为了保证数据的完整性，数据库有锁定机制。MySQL中有表锁定和行锁定，MySQL中myisam存储引擎是表锁定，innodb存储引擎是行锁定。分为包含共享锁和独占锁两种。独占锁就是整个数据文件归一个线程所有，其他线程就必须等待。如果数据太多，一次执行的时间太长，特别是在锁表的情况下，就会导致大量的其他SQL等待执行，严重影响系统的正常使用。

另外更新表数据时会导致索引更新，当单表数据量很大时这个过程比较耗时，这就是为什么对大表进行新增操作会比较慢的原因。并且更新表数据会进行表级锁或者行锁，这样就导致其他操作等待。


# mysql字段varchar区分大小写utf8_bin、utf8_general_ci编码区别

在mysql中存在着各种utf8编码格式：
utf8_bin将字符串中的每一个字符用二进制数据存储，区分大小写。
utf8_genera_ci不区分大小写，ci为case insensitive的缩写，即大小写不敏感。
utf8_general_cs区分大小写，cs为case sensitive的缩写，即大小写敏感。

用utf8_genera_ci没有区分大小写，导致这个字段的内容区分大小写时出问题，比如作为区分大小写的code或者验证码时就出问题了。
utf8_general_cs这个选项一般没有，所以只能用utf8_bin区分大小写

mysql对于类型为varchar数据默认不区分大小写，字段以“utf8_bin”编码使其区分大小写。

`code` varchar(20) CHARACTER SET utf8 COLLATE utf8_bin DEFAULT NULL COMMENT '唯一码'




# 常用的但容易忘的：

如果有主键或者唯一键冲突则不插入：insert ignore into
如果有主键或者唯一键冲突则更新,注意这个会影响自增的增量：INSERT INTO room_remarks(room_id,room_remarks) VALUE(1,"sdf") ON DUPLICATE KEY UPDATE room_remarks="234"
如果有就用新的替代，values如果不包含自增列，自增列的值会变化： REPLACE INTO room_remarks(room_id,room_remarks) VALUE(1,"sdf")
备份表：CREATE TABLE user_info SELECT * FROM user_info
复制表结构：CREATE TABLE user_v2 LIKE user
从查询语句中导入：INSERT INTO user_v2 SELECT * FROM user或者INSERT INTO user_v2(id,num) SELECT id,num FROM user
连表更新：UPDATE user a, room b SET a.num=a.num+1 WHERE a.room_id=b.id

# 优化时用到：

强制使用某个索引： select * from table force index(idx_user) limit 2;
禁止使用某个索引： select * from table ignore index(idx_user) limit 2;
禁用缓存(在测试时去除缓存的影响)： select SQL_NO_CACHE from table limit 2;
查看字符集 SHOW VARIABLES LIKE 'character_set%';
查看排序规则 SHOW VARIABLES LIKE 'collation%';


# 千万大表在线修改
mysql在表数据量很大的时候，如果修改表结构会导致锁表，业务请求被阻塞。mysql在5.6之后引入了在线更新，但是在某些情况下还是会锁表，所以一般都采用pt工具( Percona Toolkit)
如对表添加索引：
pt-online-schema-change --user='root' --host='localhost' --ask-pass --alter "add index idx_user_id(room_id,create_time)" D=fission_show_room_v2,t=room_favorite_info --execute


# sql to sqlalchemy
{

    功能说明：
    查询主键为 10004, 10001, 10006, 10003 的四位员工在 1997-12-01 时期的年薪及上年年薪，
    需 Employees，Salaries，Title 三个表联合查询。
    结果是： 返回字段为 emp_no, birth_date, first_name, last_name, gender, hire_date, 
    title(新增字段，需联表 Title), from_date, to_date, salary, last_salary
    提示：该实例很复杂，重点如下：
        1、if else 三目运算符的使用。
        2、func.date_sub 的使用。
        3、text 可以使用原始的 sql 语句。
        4、对 salaries 表同时进行两次及以上查询，用到了 aliased。
        5、使用 IFNULL 函数。


'''使用 sql 语句方式进行查询'''

SELECT
    emp.*, t.title,
    s.from_date,
    s.to_date,
    s.salary,
    IFNULL(
        (
            SELECT
                s.salary
            FROM
                salaries s
            WHERE
                s.emp_no = emp.emp_no
            AND (
                DATE_SUB(
                    DATE('1997-12-01'),
                    INTERVAL 1 YEAR
                ) BETWEEN s.from_date
                AND s.to_date
            )
        ),
        0
    ) AS last_salary
FROM
    employees emp
JOIN titles t ON emp.emp_no = t.emp_no
JOIN salaries s ON emp.emp_no = s.emp_no
WHERE
    (
        emp.emp_no = 10004
        OR emp.emp_no = 10001
        OR emp.emp_no = 10006
        OR emp.emp_no = 10003
    )
AND (
    DATE('1997-12-01') BETWEEN s.from_date
    AND s.to_date
)
AND (
    DATE('1997-12-01') BETWEEN t.from_date
    AND t.to_date
)



'''方法一：使用 if else 三目运算符'''
s1 = aliased(Salary)
s2 = aliased(Salary)
alchemy_data = session.query(Employee.emp_no, Employee.birth_date, Employee.first_name,
                                 Employee.last_name, Employee.gender, Employee.hire_date, Title.title,
                                 s1.from_date, s1.to_date, s1.salary, (0 if not
                                        session.query(s2.salary).filter(s2.emp_no==Employee.emp_no,
                                        func.date_sub(text("date('1997-12-01'), interval 1 year")).
                                        between(s2.from_date, s2.to_date))
                             else session.query(s2.salary).
        filter(s2.emp_no==Employee.emp_no, func.date_sub(text("date('1997-12-01'), interval 1 year")).
               between(s2.from_date, s2.to_date))).label("last_salary")).\
    filter(Employee.emp_no==s1.emp_no , Title.emp_no==s1.emp_no,
           or_(Employee.emp_no==10004,
               Employee.emp_no==10001,
               Employee.emp_no==10006,
               Employee.emp_no==10003),
           func.date('1997-12-01').between(s1.from_date, s1.to_date),
           func.date('1997-12-01').between(Title.from_date, Title.to_date)).all()





SELECT
    emp.*, t.title,
    CONCAT_WS('--', s.from_date, s.to_date) AS 'times',
    s.salary
FROM
    employees emp
JOIN titles t ON emp.emp_no = t.emp_no
JOIN salaries s ON emp.emp_no = s.emp_no
WHERE
    emp.emp_no = 10004
AND (
    s.from_date BETWEEN t.from_date
    AND t.to_date
)


'''使用 sqlalchemy 方式进行查询'''
alchemy_data = session.query(Employee.emp_no, Employee.birth_date, Employee.first_name,
                                 Employee.last_name, Employee.gender, Employee.hire_date, Title.title,
                                 func.concat_ws('--', Salary.from_date, Salary.to_date).label('times'),
                                 Salary.salary).\
    filter(Employee.emp_no == 10004, Salary.emp_no == 10004, Title.emp_no == 10004,
           Salary.from_date.between(Title.from_date, Title.to_date)).all()


           
'''使用 sql 语句方式进行查询'''

SELECT
    e.emp_no,
    e.birth_date,
    e.first_name,
    e.last_name,
    (
        CASE e.gender
        WHEN 'M' THEN
            'nan'
        WHEN 'F' THEN
            'nv'
        ELSE
            'qita'
        END
    ) as gender,
    e.hire_date
FROM
    employees e
LIMIT 10 OFFSET 4

sql_data = [(d.emp_no, d.birth_date, d.first_name, d.last_name, d.gender, d.hire_date) for d in session.execute(sql)]

'''使用 sqlalchemy 方式进行查询'''
'''第一种方法
alchemy_data = session.query(Employee.emp_no, Employee.birth_date, Employee.first_name, Employee.last_name,
                             case([(Employee.gender=='M', 'nan'), (Employee.gender=='F', 'nv')],
                                  else_='qita').label('gender'),
                             Employee.hire_date).limit(10).offset(4).all()
'''

'''第二种方法'''
alchemy_data = session.query(Employee.emp_no, Employee.birth_date, Employee.first_name, Employee.last_name,
                             case({'M': 'nan', 'F': 'nv'},
                                  value=Employee.gender,
                                  else_='qita').label('gender'),
                             Employee.hire_date).limit(10).offset(4).all()

}

# sqlalchemy 一对多新增数据的四种方式
{
# 设置关系属性
books=db.relationship('Book',backref='author',lazy='dynamic')
创建两个表
# 作者表
class Author(db.Model):
    # 定义表名
    __tablename__='authors'
    id=db.Column(db.INTEGER,primary_key=True)
    name=db.Column(db.String(30),unique=True)
    books=db.relationship('Book',backref='autho')

# 书籍表
class Book(db.Model):
    __tablename__='books'
    id=db.Column(db.INTEGER,primary_key=True)
    name=db.Column(db.String(20))
    author_id=db.Column(db.INTEGER,db.ForeignKey('authors.id'))

# 提交表数据的不同写法
{
#1 如果没有设置关系属性,只使用外键的话,需要先提交外键表对应的主键表中的信息,因为如果没有提交,主键的id没有生成,则外键对应的字段为空,信息有误,以下代码:
else:
		# 先提交author表信息,生成主键id
        aut=Author(name=au_name)
        db.session.add(aut)
        db.session.commit()
        # 提交book表信息,
        book=Book(name=bk_name,author_id=aut.id)
        db.session.add(book)
        # print(aut.name,book.author_id)
        db.session.commit()
    

#2 [建议] 如果设置了关系属性,当使用append来关联数据的时候,可以两个表的信息可以最后一期提交
else:
        author=Author(name=au_name)
        book=Book(name=bk_name) # "author_id" 可写可不写,因为下边会append关联属性
        # book=Book(name=bk_name,author_id=author.id)
        author.books.append(book)
        db.session.add_all([book,author])
        db.session.commit()

#3 如果设置了关系属性,但是不使用append来关联数据的话,只是用数据绑定外键的话,还是要先提交主键表数据,生成id主键后再提交多的一方信息表数据,与1类似.
else:
		# 先提交author表信息,生成主键id
        aut=Author(name=au_name)
        db.session.add(aut)
        db.session.commit()
        # 提交book表信息,
        book=Book(name=bk_name,author_id=aut.id)
        db.session.add(book)
        # print(aut.name,book.author_id)
        db.session.commit()


#4 也可以这样
        aut=Author(name=au_name)
        # 提交book表信息,
        book=Book(name=bk_name)
        aut.books=[book]
        db.session.add(aut)
        db.session.commit()
        
        

# 是用个一对多插入时的原sql
{
INSERT INTO `Truck` (plate, vehicle_no, length, wide, high, weight, volume, type, run_mode, vehicle_type, qr_code, line_property, is_temp_truck, is_forbidden, org_code, carrier_name, carrier_code, fk_carrier_id, if_valid, create_time, update_time, is_onway, plate_type, line_type) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
2018-11-22 12:09:50,405 INFO sqlalchemy.engine.base.Engine ('\xe6\xb5\x99A64647', None, u'111', None, None, u'100', u'', u'1', None, '\xe8\xbd\xa6\xe8\xbe\x86\xe5\x9e\x8b\xe5\x8f\xb7', None, None, 1, 1, None, None, None, None, 1, datetime.datetime(2018, 11, 22, 12, 9, 50, 398000), None, 0, None, 'BC')

INSERT INTO truck_info (truck_id, vehicle_type, brand, vehicle_model, engine_model, power, horsepower, vin, box_length, box_width, box_height, box_type, total_mass, equipment_mass, limit_mass, limit_person, belong_to, purchase_at, abolish_at, vehicle_license_no, voc_no, insurance_start, insurance_end, insurance_com, insurance_amount, url_vehicle_license, url_voc, url_vrc, url_truck_jqx, url_truck_syx) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
2018-11-22 12:09:50,430 INFO sqlalchemy.engine.base.Engine (59205L, '\xe8\xbd\xa6\xe8\xbe\x86\xe5\x9e\x8b\xe5\x8f\xb7', '', '\xe8\xbd\xa6\xe8\xbe\x86\xe5\x9e\x8b\xe5\x8f\xb7', '\xe5\x8f\x91\xe5\x8a\xa8\xe6\x9c\xba\xe5\x8f\xb7\xe7\xa0\x81', u'1', u'1.36', '11111', u'', u'', u'', u'1', u'100', u'200', u'300', u'40', '\xe6\xb5\x8b\xe8\xaf\x95', u'2018-11-22', u'2033-11-26', u'', '', u'2018-11-08', u'2018-11-15', '\xe5\x95\x8a', u'10000', '', '', '', '', '')

INSERT INTO truck_org (truck_id, org_id, status, reason, create_time, update_time) VALUES (%s, %s, %s, %s, %s, %s)
2018-11-22 12:09:50,436 INFO sqlalchemy.engine.base.Engine (59205L, u'1', 1, '', datetime.datetime(2018, 11, 22, 12, 9, 50, 399000), None)


}
}
# 原文：https://blog.csdn.net/sinat_42194124/article/details/82797091 
}

# sqlalchemy 一对多修改数据的方式 --- 单独修改,不要driver_obj.user_org = [driver_org_history_obj]
{
driver_obj.fk_dept_id = org_id
driver_org_history_obj.status = 1
driver_org_history_obj.reason = None
driver_org_history_obj.update_time = datetime.datetime.now()
db.session.commit()

}





# sqlalchemy is null
{

# 方法一
session.query(employee).filter_by(employ.brand_id.isnot(None))
# 方法二
from sqlalchemy import not_
session.query(employee).filter_by(not_(employ.brand_id==None))
}

#sql过滤    
print(session.query(User).filter("id>:id").params(id=1).all())  

#exists    
print(session.query(User).filter(exists().where(Address.user_id == User.id)))    
print(session.query(User).filter(User.addresses.any()))


from sqlalchemy import distinct
from sqlalchemy.orm import aliased
 
Friend = aliased(User, name='Friend')
print session.query(User.id).join(Friendship, User.id == Friendship.user_id1).all() # 所有有朋友的用户
print session.query(distinct(User.id)).join(Friendship, User.id == Friendship.user_id1).all() # 所有有朋友的用户（去掉重复的）
print session.query(User.id).join(Friendship, User.id == Friendship.user_id1).distinct().all() # 同上
print session.query(Friendship.user_id2).join(User, User.id == Friendship.user_id1).order_by(Friendship.user_id2).distinct().all() # 所有被别人当成朋友的用户
print session.query(Friendship.user_id2).select_from(User).join(Friendship, User.id == Friendship.user_id1).order_by(Friendship.user_id2).distinct().all() # 同上，join 的方向相反，但因为不是 STRAIGHT_JOIN，所以 MySQL 可以自己选择顺序
print session.query(User.id, Friendship.user_id2).join(Friendship, User.id == Friendship.user_id1).all() # 用户及其朋友
print session.query(User.id, Friendship.user_id2).join(Friendship, User.id == Friendship.user_id1).filter(User.id < 10).all() # id 小于 10 的用户及其朋友
print session.query(User.id, Friend.id).join(Friendship, User.id == Friendship.user_id1).join(Friend, Friend.id == Friendship.user_id2).all() # 两次 join，由于使用到相同的表，因此需要别名
print session.query(User.id, Friendship.user_id2).outerjoin(Friendship, User.id == Friendship.user_id1).all() # 用户及其朋友（无朋友则为 None，使用左连接）



# None 不可迭代
'a' not in None
Traceback (most recent call last):
  File "<input>", line 1, in <module>
TypeError: argument of type 'NoneType' is not iterable


# sqlalchemy 
{
http://www.codexiu.cn/python/SQLAlchemy%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/73/530/  # 不错的系列文章

1.定义关系, 必有使用 ForeignKey 约束. 当然, 这里说的只是在定义模型时必有要有, 至于数据库中是否真有外键约定, 这并不重要.关系只是 SQLAlchemy 提供的工具, 与数据库无关, 所以任何时候添加都是可以的.

2.session.flush()的作用
session = Session()
user = User(name='first', username=u'新的')
session.add(user)
session.flush() # 是进行数据库交互, 但是事务并没有提交. 进行数据库交互之后, user.id 才有值.
blog = Blog(title=u'第一个', user=user.id)
session.add(blog)
session.commit()


# TypeError: expected string or Unicode object, long found 一般都是数据库返回的数据格式和model不服

class User(BaseModel):
    __tablename__ = 'user'

    id = Column(BIGINT, primary_key=True, autoincrement=True)
    name = Column(String(32), server_default='', nullable=False)

    blog_list = relationship('Blog', order_by='Blog.create', lazy="dynamic")
    
# 获取实例时自由控制:
session.query(User).get(1).blog_list.all()
session.query(User).get(1).blog_list.filter(Blog.title == 'abc').first()


# 关系的查询
关系定义之后, 除了在查询时会有自动关联的效果, 在作查询时, 也可以对定义的关系做操作:

class Blog(BaseModel):
    __tablename__ = 'blog'

    id = Column(Integer, autoincrement=True, primary_key=True)
    title = Column(Unicode(32), server_default='')
    user = Column(Integer, ForeignKey('user.id'), index=True)

    user_obj = relationship('User')


class User(BaseModel):
    __tablename__ = 'user'

    id = Column(Integer, autoincrement=True, primary_key=True)
    name = Column(Unicode(32), server_default='')

    blogs = relationship('Blog')
对于 一对多 的关系, 使用 any() 函数查询:

user = session.query(User).filter(User.blogs.any(Blog.title == u'A')).first()
SQLAlchemy 会使用 exists 条件, 类似于:

SELECT *
FROM user
WHERE EXISTS
    (SELECT 1
     FROM blog
     WHERE user.id = blog.user AND blog.title = ?)
 LIMIT ? OFFSET ?
反之, 如果是 多对一 的关系, 则使用 has() 函数查询:

blog = session.query(Blog).filter(Blog.user_obj.has(User.name == u'XX')).first()
最后的 SQL 语句都是一样的.



# SQLAlchemy字段类型
字段类型是在定义模型时, 对每个 Column 的类型约定. 不同类型的字段类型在输入输出上, 及支持的操作方面, 有所区别.

这里只介绍 sqlalchemy.types.* 中的类型, SQL 标准类型方面, 是写什么最后生成的 DDL 语句就是什么, 比如 BIGINT, BLOG 这些, 但是这些类型并不一定在所有数据库中都有支持. 除此而外, SQLAlchemy 也支持一些特定数据库的特定类型, 这些需要从具体的 dialects 实现里导入.

Integer/BigInteger/SmallInteger
整形.
Boolean
布尔类型. Python 中表现为 True/False , 数据库根据支持情况, 表现为 BOOLEAN 或SMALLINT . 实例化时可以指定是否创建约束(默认创建).
Date/DateTime/Time (timezone=False)
日期类型, Time 和 DateTime 实例化时可以指定是否带时区信息.
Interval
时间偏差类型. 在 Python 中表现为 datetime.timedelta() , 数据库不支持此类型则存为日期.
Enum (*enums, **kw)
枚举类型, 根据数据库支持情况, SQLAlchemy 会使用原生支持或者使用 VARCHAR 类型附加约束的方式实现. 原生支持中涉及新类型创建, 细节在实例化时控制.
Float
浮点小数.
Numeric (precision=None, scale=None, decimal_return_scale=None, ...)
定点小数, Python 中表现为 Decimal .
LargeBinary (length=None)
字节数据. 根据数据库实现, 在实例化时可能需要指定大小.
PickleType
Python 对象的序列化类型.
String (length=None, collation=None, ...)
字符串类型, Python 中表现为 Unicode , 数据库表现为 VARCHAR , 通常都需要指定长度.
Unicode
类似与字符串类型, 在某些数据库实现下, 会明确表示支持非 ASCII 字符. 同时输入输出也强制是 Unicode 类型.
Text
长文本类型, Python 表现为 Unicode , 数据库表现为 TEXT .
UnicodeText
参考 Unicode .



from sqlalchemy import func, or_, not_
 
user = User(name='a')
session.add(user)
user = User(name='b')
session.add(user)
user = User(name='a')
session.add(user)
user = User()
session.add(user)
session.commit()
 
query = session.query(User)
print query # 显示SQL 语句
print query.statement # 同上
for user in query: # 遍历时查询
    print user.name
print query.all() # 返回的是一个类似列表的对象
print query.first().name # 记录不存在时，first() 会返回 None
# print query.one().name # 不存在，或有多行记录时会抛出异常
print query.filter(User.id == 2).first().name
print query.get(2).name # 以主键获取，等效于上句
print query.filter('id = 2').first().name # 支持字符串
 
query2 = session.query(User.name)
print query2.all() # 每行是个元组
print query2.limit(1).all() # 最多返回 1 条记录
print query2.offset(1).all() # 从第 2 条记录开始返回
print query2.order_by(User.name).all()
print query2.order_by('name').all()
print query2.order_by(User.name.desc()).all()
print query2.order_by('name desc').all()
print session.query(User.id).order_by(User.name.desc(), User.id).all()
 
print query2.filter(User.id == 1).scalar() # 如果有记录，返回第一条记录的第一个元素
print session.query('id').select_from(User).filter('id = 1').scalar()
print query2.filter(User.id > 1, User.name != 'a').scalar() # and
query3 = query2.filter(User.id > 1) # 多次拼接的 filter 也是 and
query3 = query3.filter(User.name != 'a')
print query3.scalar()
print query2.filter(or_(User.id == 1, User.id == 2)).all() # or
print query2.filter(User.id.in_((1, 2))).all() # in
 
query4 = session.query(User.id)
print query4.filter(User.name == None).scalar()
print query4.filter('name is null').scalar()
print query4.filter(not_(User.name == None)).all() # not
print query4.filter(User.name != None).all()
 
print query4.count()
print session.query(func.count('*')).select_from(User).scalar()
print session.query(func.count('1')).select_from(User).scalar()
print session.query(func.count(User.id)).scalar()
print session.query(func.count('*')).filter(User.id > 0).scalar() # filter() 中包含 User，因此不需要指定表
print session.query(func.count('*')).filter(User.name == 'a').limit(1).scalar() == 1 # 可以用 limit() 限制 count() 的返回数
print session.query(func.sum(User.id)).scalar()
print session.query(func.now()).scalar() # func 后可以跟任意函数名，只要该数据库支持
print session.query(func.current_timestamp()).scalar()
print session.query(func.md5(User.name)).filter(User.id == 1).scalar()
 
query.filter(User.id == 1).update({User.name: 'c'})
user = query.get(1)
print user.name
 
user.name = 'd'
session.flush() # 写数据库，但并不提交
print query.get(1).name
 
session.delete(user)
session.flush()
print query.get(1)
 
session.rollback()
print query.get(1).name
query.filter(User.id == 1).delete()
session.commit()
print query.get(1)



#如何替换一个已有主键的记录？
使用 session.merge() 方法替代 session.add()，其实就是 SELECT + UPDATE：

user = User(id=1, name='ooxx')
session.merge(user)
session.commit()


# 如何指定使用 InnoDB，以及使用 UTF-8 编码？
最简单的方式就是修改数据库的默认配置。如果非要在代码里指定的话，可以这样：

class User(BaseModel):
    __table_args__ = {
        'mysql_engine': 'InnoDB',
        'mysql_charset': 'utf8'


# 如何连接表？
from sqlalchemy import distinct
from sqlalchemy.orm import aliased
 
Friend = aliased(User, name='Friend')
print session.query(User.id).join(Friendship, User.id == Friendship.user_id1).all() # 所有有朋友的用户
print session.query(distinct(User.id)).join(Friendship, User.id == Friendship.user_id1).all() # 所有有朋友的用户（去掉重复的）
print session.query(User.id).join(Friendship, User.id == Friendship.user_id1).distinct().all() # 同上
print session.query(Friendship.user_id2).join(User, User.id == Friendship.user_id1).order_by(Friendship.user_id2).distinct().all() # 所有被别人当成朋友的用户
print session.query(Friendship.user_id2).select_from(User).join(Friendship, User.id == Friendship.user_id1).order_by(Friendship.user_id2).distinct().all() # 同上，join 的方向相反，但因为不是 STRAIGHT_JOIN，所以 MySQL 可以自己选择顺序
print session.query(User.id, Friendship.user_id2).join(Friendship, User.id == Friendship.user_id1).all() # 用户及其朋友
print session.query(User.id, Friendship.user_id2).join(Friendship, User.id == Friendship.user_id1).filter(User.id < 10).all() # id 小于 10 的用户及其朋友
print session.query(User.id, Friend.id).join(Friendship, User.id == Friendship.user_id1).join(Friend, Friend.id == Friendship.user_id2).all() # 两次 join，由于使用到相同的表，因此需要别名
print session.query(User.id, Friendship.user_id2).outerjoin(Friendship, User.id == Friendship.user_id1).all() # 用户及其朋友（无朋友则为 None，使用左连接）


#in_出来的无法删除,解决办法就是删除时不进行同步，然后再让 session 里的所有实体都过期：
session.query(User).filter(User.id.in_((1, 2, 3))).delete(synchronize_session=False)


#如何对一个字段进行自增操作？
最简单的办法就是获取时加上写锁：

user = session.query(User).with_lockmode('update').get(1)
user.age += 1
session.commit()
如果不想多一次读的话，这样写也是可以的：
session.query(User).filter(User.id == 1).update({
    User.age: User.age + 1
})
session.commit()
# 其实字段之间也可以做运算：
session.query(User).filter(User.id == 1).update({
    User.age: User.age + User.id
})



## 修改
还是通常的两种方式:

session.query(User).filter(User.username == 'abc').update({'name': '123'})
session.commit()

user = session.query(User).filter_by(username='abc').scalar()
user.name = '223'
session.commit()
如果涉及对属性原值的引用, 则要考虑 synchronize_session 这个参数.

'evaluate' 默认值, 会同时修改当前 session 中的对象属性.
'fetch' 修改前, 会先通过 select 查询条目的值.
False 不修改当前 session 中的对象属性.
在默认情况下, 因为会有修改当前会话中的对象属性, 所以如果语句中有 SQL 函数, 或者"原值引用", 那是无法完成的操作, 自然也会报错, 比如:

from sqlalchemy import func
session.query(User).update({User.name: func.trim('123 ')})
session.query(User).update({User.name: User.name + 'x'})
这种情况下, 就不能要求 SQLAlchemy 修改当前 session 的对象属性了, 而是直接进行数据库的交互, 不管当前会话值:

session.query(User).update({User.name: User.name + 'x'}, synchronize_session=False)
是否修改当前会话的对象属性, 涉及到当前会话的状态. 如果当前会话过期, 那么在获取相关对象的属性值时, SQLAlchemy 会自动作一次数据库查询, 以便获取正确的值:

user = session.query(User).filter_by(username='abc').scalar()
print user.name
session.query(User).update({User.name: 'new'}, synchronize_session=False)
print user.name
session.commit()
print user.name
执行了 update 之后, 虽然相关对象的实际的属性值已变更, 但是当前会话中的对象属性值并没有改变. 直到 session.commit() 之后, 当前会话变成"过期"状态, 再次获取 user.name 时, SQLAlchemy 通过 user 的 id 属性, 重新去数据库查询了新值. (如果 user 的 id 变了呢? 那就会出事了啊.)

synchronize_session 设置成 'fetch' 不会有这样的问题, 因为在做 update 时已经修改了当前会话中的对象了.

不管 synchronize_session 的行为如何, commit 之后 session 都会过期, 再次获取相关对象值时, 都会重新作一次查询.




}
}

# Flask request获取参数问题
{
print("request.path:", request.path)
print("request.form:", request.form, type(request.form))
print("request.args:", request.args, type(request.args))
print("request.values:", request.values, type(request.values))
print("session:", sessions, type(sessions))
print('request.get_json:', request.get_json(force=False), type(request.get_json(force=False)))  # dict
print("request.json:", request.json, type(request.json))  # dict
print("request.get_data:", request.get_data(), type(request.get_data()))  # str
print("request.data:", request.data, type(request.data))  # str
        

        
curl -H "Content-Type: application/json" -X POST "http://172.16.2.195:3000/users/id"  -d '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}'

('request.path:', u'/users/id')
('request.form:', ImmutableMultiDict([]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.args:', ImmutableMultiDict([]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.values:', CombinedMultiDict([ImmutableMultiDict([]), ImmutableMultiDict([])]), <class 'werkzeug.datastructures.CombinedMultiDict'>)
('session:', <SecureCookieSession {}>, <class 'werkzeug.local.LocalProxy'>)
('request.get_json:', {u'a': 1, u'token': u'6f71c800-f850-11e8-8e95-6c4b90cecece', u'id': 2123}, <type 'dict'>)
('request.json:', {u'a': 1, u'token': u'6f71c800-f850-11e8-8e95-6c4b90cecece', u'id': 2123}, <type 'dict'>)
('request.get_data:', '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}', <type 'str'>)
('request.data:', '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}', <type 'str'>)



curl -H "Content-Type: application/json" -X GET "http://172.16.2.195:3000/users/id?get1=12345&get2=42131"  -d '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}'

('request.path:', u'/users/id')
('request.form:', ImmutableMultiDict([]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.args:', ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.values:', CombinedMultiDict([ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), ImmutableMultiDict([])]), <class 'werkzeug.datastructures.CombinedMultiDict'>)
('session:', <SecureCookieSession {}>, <class 'werkzeug.local.LocalProxy'>)
('request.get_json:', {u'a': 1, u'token': u'6f71c800-f850-11e8-8e95-6c4b90cecece', u'id': 2123}, <type 'dict'>)
('request.json:', {u'a': 1, u'token': u'6f71c800-f850-11e8-8e95-6c4b90cecece', u'id': 2123}, <type 'dict'>)
('request.get_data:', '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}', <type 'str'>)
('request.data:', '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}', <type 'str'>)


curl -H "Content-Type: application/json" -X POST "http://172.16.2.195:3000/users/id?get1=12345&get2=42131"  -d '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}'

('request.path:', u'/users/id')
('request.form:', ImmutableMultiDict([]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.args:', ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.values:', CombinedMultiDict([ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), ImmutableMultiDict([])]), <class 'werkzeug.datastructures.CombinedMultiDict'>)
('session:', <SecureCookieSession {}>, <class 'werkzeug.local.LocalProxy'>)
('request.get_json:', {u'a': 1, u'token': u'6f71c800-f850-11e8-8e95-6c4b90cecece', u'id': 2123}, <type 'dict'>)
('request.json:', {u'a': 1, u'token': u'6f71c800-f850-11e8-8e95-6c4b90cecece', u'id': 2123}, <type 'dict'>)
('request.get_data:', '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}', <type 'str'>)
('request.data:', '{"a":1,"id":2123,"token":"6f71c800-f850-11e8-8e95-6c4b90cecece"}', <type 'str'>)


curl -X POST "http://172.16.2.195:3000/users/id?get1=12345&get2=42131"  -d 'a=1&id=2123&token=6f71c800-f850-11e8-8e95-6c4b90cecece'

('request.path:', u'/users/id')
('request.form:', ImmutableMultiDict([('a', u'1'), ('token', u'6f71c800-f850-11e8-8e95-6c4b90cecece'), ('id', u'2123')]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.args:', ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.values:', CombinedMultiDict([ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), ImmutableMultiDict([('a', u'1'), ('token', u'6f71c800-f850-11e8-8e95-6c4b90cecece'), ('id', u'2123')])]), <class 'werkzeug.datastructures.CombinedMultiDict'>)
('session:', <SecureCookieSession {}>, <class 'werkzeug.local.LocalProxy'>)
('request.get_json:', None, <type 'NoneType'>)
('request.json:', None, <type 'NoneType'>)
('request.get_data:', '', <type 'str'>)
('request.data:', '', <type 'str'>)


curl -X GET "http://172.16.2.195:3000/users/id?get1=12345&get2=42131"  -d 'a=1&id=2123&token=6f71c800-f850-11e8-8e95-6c4b90cecece'

('request.path:', u'/users/id')
('request.form:', ImmutableMultiDict([('a', u'1'), ('token', u'6f71c800-f850-11e8-8e95-6c4b90cecece'), ('id', u'2123')]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.args:', ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), <class 'werkzeug.datastructures.ImmutableMultiDict'>)
('request.values:', CombinedMultiDict([ImmutableMultiDict([('get1', u'12345'), ('get2', u'42131')]), ImmutableMultiDict([('a', u'1'), ('token', u'6f71c800-f850-11e8-8e95-6c4b90cecece'), ('id', u'2123')])]), <class 'werkzeug.datastructures.CombinedMultiDict'>)
('session:', <SecureCookieSession {}>, <class 'werkzeug.local.LocalProxy'>)
('request.get_json:', None, <type 'NoneType'>)
('request.json:', None, <type 'NoneType'>)
('request.get_data:', '', <type 'str'>)
('request.data:', '', <type 'str'>)

}




chrome://net-internals/#dns








